{"cells":[
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "%matplotlib inline\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import label_binarize, normalize, LabelEncoder\nfrom sklearn.metrics import log_loss\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, train_test_split\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.linear_model import SGDClassifier\n\nfrom xgboost import XGBClassifier\nimport xgboost as xgb"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df = pd.read_csv('../input/train.csv')\ndf.info()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df.head()"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Obviously the age of the animals should be importante, so we need to clean it up a bit.\nFrom the frist lines we can see that the age is in the format Numberperiod. \n\nLets see what periods are there."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df['AgeuponOutcome'].str.split(expand=True)[1].unique()"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "So lets map each of these to a \"multiplier\", and calculate the age of the animals in days."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "time_multiplier = dict(year = 365, years=365, weeks = 7, month = 30, months=30, days = 1, week = 7, day= 1)\nfoo = df['AgeuponOutcome'].str.split(expand=True)\nage = foo[0].astype('float32')\nperiod = foo[1]\ndel foo\nperiod = period.map(time_multiplier)\ndf['age_in_days'] = age * period"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print(df['SexuponOutcome'].str.split(expand=True)[0].unique())\nprint(df['SexuponOutcome'].str.split(expand=True)[1].unique())"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "foo = df['SexuponOutcome'].str.split(expand=True)\ndf['condition'] = foo[0].map({'Neutered': 'operated', 'Spayed':'operated', 'Intact': 'intact', 'Unknown': 'unknown'})\ndf['sex'] = foo[1]\nsns.countplot(x='OutcomeType', data=df)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "So, it looks like most of the animals are being adopted or transfered. With some returning to their owner.\nOnly a small part of them are suffering euthanasia or dying (thanks god).\n\nBut how are these outcomes related to other characteristics of the animal? Are dogs and cats being are threated alike?"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "sns.countplot(x='OutcomeType', data=df, hue='AnimalType')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Dogs are prefered (as one would expect). The vast majority the animals returned to their owner are dogs. \nDogs also haave a nice leading on adoption rate.\n \nWhat about the sex?"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "sns.countplot(x='OutcomeType', data=df, hue='sex')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "So, in general the sex of the animal doesn't appear to have much influence on their final destinty."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "sns.countplot(x='OutcomeType', data=df, hue='condition')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Thats not the case when dealing on the codition of the animal. Most of the adopted or returned animals are operated.\n\nNow lets see how the age influences this, for this we will use a boxplot."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "sns.boxplot(x='OutcomeType', y='age_in_days', data=df, showfliers=False) #showfliers=false disable the display of the outliers"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Contrary to my initial expectations, young animals are the ones that die most, while old animmals return to their owner (the owner miss them?) or suffer from euthanasia (putting their out of their misery).\n\nAdoptions are mainly about youg animals.\n\nLets see how the name of the animals influence their odds."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df['has_name'] = pd.notnull(df['Name'])\nsns.countplot(x='OutcomeType', data=df, hue='has_name')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "So, if the animal has a name people are more propensed to get them back or even adopt them (I get the case of return_to_owner, but... can't new owners give their pets a name?)."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df['pure_breed'] = df.Breed.apply(lambda x : 'mix' not in x.lower())\nsns.countplot(x='OutcomeType', data=df, hue='pure_breed')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df.DateTime = pd.to_datetime(df.DateTime)\ndf['month'] = df.DateTime.dt.month.astype('category')\ndf['weekday'] = df.DateTime.dt.weekday.astype('category')\ndf['hour'] = df.DateTime.dt.hour.astype('category')\nsns.countplot(x='OutcomeType', data=df, hue='month')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "sns.countplot(x='OutcomeType', data=df, hue='weekday')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "sns.countplot(x='OutcomeType', data=df, hue='hour')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "color_split = df.Color.str.split('/', expand=True)\ndf['color_1'] = color_split[0]\nprint(df.color_1.unique())\ndf['color_2'] = color_split[1]\nprint(df.color_2.unique())"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print(df.Breed.value_counts()[:10])\nprint('---------')\nprint(df.Breed.str.replace(' Mix', '').value_counts()[:10])\nprint()\nprint()\nprint(len(df.Breed.value_counts()))\nprint(len(df.Breed.str.replace(' Mix', '').value_counts()))\ndf.Breed.value_counts()\ndf['breed_rarity']=  pd.cut(df.Breed.value_counts(), 5, include_lowest=True, labels=['super rare', 'rare', 'comon', 'very comon', 'very very common' ])"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "y = df['OutcomeType']\nx = df[['age_in_days','condition', 'sex','AnimalType', 'has_name', 'color_1', 'color_2', 'pure_breed', 'breed_rarity', 'hour', 'weekday', 'month']]\nx = pd.get_dummies(x)\nx.info(null_counts=True, memory_usage='deep', verbose=True)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Age in days has some null values. Lets fix it."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df2 = df[['OutcomeType', 'age_in_days','condition', 'sex','AnimalType', 'has_name', 'color_1', 'color_2', 'pure_breed', 'breed_rarity', 'hour', 'weekday', 'month']]\ndf2 = pd.get_dummies(df2.reindex(), columns=['condition', 'sex','AnimalType', 'has_name', 'color_1', 'color_2', 'pure_breed', 'breed_rarity', 'hour', 'weekday', 'month'])\ndf2.dropna(axis=0, inplace=True)\ny = df2['OutcomeType']\ny = LabelEncoder().fit_transform(y)\nx = df2.drop('OutcomeType', axis=1)\nprint(x.shape)\nprint(y.shape)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "rf = RandomForestClassifier()\nrf.fit(x, y)\n\ny_pred = rf.predict_proba(x)\nprint(log_loss(y, y_pred))"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('Top features')\nfor score, feat in sorted(zip(rf.feature_importances_, x.columns), reverse=True)[:10]:\n    print('{:.3f} {}'.format(score,feat))\nprint()    \nprint('Botton features')\nfor score, feat in sorted(zip(rf.feature_importances_, x.columns), reverse=True)[-20:]:\n    print('{:.5f} {}'.format(score,feat))"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "So age in days is really important... What if we bin it?\n \nAlso breed_rarity didn't help a bit. So lets remove it."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df['age_bined']=  pd.cut(df.age_in_days, 10, include_lowest=True)\n\ndf2 = df[['age_bined', 'OutcomeType', 'condition', 'sex','AnimalType', 'has_name', 'color_1', 'color_2', 'pure_breed', 'hour', 'weekday', 'month']]\ndf2 = pd.get_dummies(df2.reindex(), columns=['age_bined', 'condition', 'sex','AnimalType', 'has_name', 'color_1', 'color_2', 'pure_breed', 'hour', 'weekday', 'month'])\ndf2.dropna(axis=0, inplace=True)\ny = df2['OutcomeType']\ny = LabelEncoder().fit_transform(y)\nx = df2.drop('OutcomeType', axis=1)\n\nprint(x.shape)\nprint(y.shape)\n\nrf = RandomForestClassifier(n_estimators=30, max_depth=None)\nrf.fit(x, y)\ny_pred = rf.predict_proba(x)\nprint(log_loss(y, y_pred))"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('Top features')\nfor score, feat in sorted(zip(rf.feature_importances_, x.columns), reverse=True)[:10]:\n    print('{:.3f} {}'.format(score,feat))\nprint()    \nprint('Botton features')\nfor score, feat in sorted(zip(rf.feature_importances_, x.columns), reverse=True)[-10:]:\n    print('{:.5f} {}'.format(score,feat))"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "So... binning the age didn't help a bit... Lets keep the age_in_days.\n \nWe can try using the breed information to augment the dataset, but its too large (lots of different values).\nWe can use it, but first we have to reduce the number of feature (columns) using PCA."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "breed = PCA(0.90).fit_transform(pd.get_dummies(df['Breed']))\nprint(breed.shape)\n\nbreed = pd.DataFrame(breed, columns=['breed_' + str(i) for i in range(breed.shape[1]) ])"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df2 = df[['age_in_days', 'OutcomeType', 'condition', 'sex','AnimalType', 'has_name', 'color_1', 'color_2', 'pure_breed', 'hour', 'weekday', 'month']]\ndf2 = pd.get_dummies(df2.reindex(), columns=['condition', 'sex','AnimalType', 'has_name', 'color_1', 'color_2', 'pure_breed', 'hour', 'weekday', 'month'])\ndf2 = pd.concat((df2, breed), axis=1)\n\ndf2.dropna(axis=0, inplace=True)\ny = df2['OutcomeType']\ny = LabelEncoder().fit_transform(y)\nx = df2.drop('OutcomeType', axis=1)\n\nrf = RandomForestClassifier(n_estimators=30, max_depth=None)\nrf.fit(x, y)\ny_pred = rf.predict_proba(x)\nprint(log_loss(y, y_pred))"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('Top features')\nfor score, feat in sorted(zip(rf.feature_importances_, x.columns), reverse=True)[:10]:\n    print('{:.3f} {}'.format(score,feat))\nprint()    \nprint('Botton features')\nfor score, feat in sorted(zip(rf.feature_importances_, x.columns), reverse=True)[-10:]:\n    print('{:.5f} {}'.format(score,feat))"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "While not among the top 10 features, obviously the breed of the animal helped a bit\n \nLets see how our model behaves on unseen data. To do it we will do crossvalidation"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "cross_val_score(RandomForestClassifier(), x, y , cv =3, scoring='log_loss')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "eek! This is bad! The predictions are really BAD. But on the training set all was good... This indicates a problem of overfitting: the model understands the training really well but can't generalize to unseen problems.\nWhen dealing with trees one way to overcome this is to control the max_depth of the tree. Lets see how this influences the predictions."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "X_train, X_test, y_train,  y_test = train_test_split(x, y)\ndepth = list(range(1, 30, 2))\ntest_score = []\ntrain_score = []\nfor d in depth:\n    rfc = RandomForestClassifier(max_depth=d)\n    rfc.fit(X_train, y_train)\n    train_score.append(log_loss(y_train, rfc.predict_proba(X_train)))\n    test_score.append(log_loss(y_test, rfc.predict_proba(X_test)))\n\nax = sns.pointplot(depth, train_score, color='red')\nax = sns.pointplot(depth, test_score, color='blue')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Thats the problem! The depth plays an important role here. Until depth is 9-10 all is good and is helps lower the training scores (a bit), but when we go above 13 the test results start increasing REALLY fast. So lets keep the depth at check with a value of 10.\n\nAs our data is also very unbalanced (very few animals die), we might take a look at the min_samples_leaf variable on RandomForests as well (this contrl how many itens must be at the leaf)."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "min_samples_leaf = list(range(1, 50, 2))\ntest_score = []\ntrain_score = []\nfor m in min_samples_leaf:\n    rfc = RandomForestClassifier(max_depth=10, min_samples_leaf= m, random_state=42)\n    rfc.fit(X_train, y_train)\n    train_score.append(log_loss(y_train, rfc.predict_proba(X_train)))\n    test_score.append(log_loss(y_test, rfc.predict_proba(X_test)))\n\nax = sns.pointplot(min_samples_leaf, train_score, color='red')\nax = sns.pointplot(min_samples_leaf, test_score, color='blue')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "estimators = list(range(10, 150, 10))\ntest_score = []\ntrain_score = []\nfor e in estimators:\n    rfc = RandomForestClassifier(max_depth=15, min_samples_leaf=1, random_state=42, n_estimators=e)\n    rfc.fit(X_train, y_train)\n    train_score.append(log_loss(y_train, rfc.predict_proba(X_train)))\n    test_score.append(log_loss(y_test, rfc.predict_proba(X_test)))\n\nax = sns.pointplot(estimators, train_score, color='red')\nax = sns.pointplot(estimators, test_score, color='blue')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "So, above 40 trees we don't see much improvement? But maybe, now that we have more trees some of the other parameters can be changed. While we could go back and check max_depth and min_samples_leaf with the new values there is a better way: grid search with cross validation."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "rfc_params = {\n    'n_estimators' : np.linspace(10,60, 3, dtype='int'),\n    'max_depth': np.linspace(2, 30, 3, dtype='int'),\n    'criterion' : ['gini', 'entropy'],\n    'min_samples_leaf': np.linspace(1, 15, 3, dtype='int'),    \n}\ngrid = GridSearchCV(RandomForestClassifier(), rfc_params, verbose=0, scoring='log_loss', n_jobs=-1)\ngrid.fit(x, y)\nprint(grid.best_score_)\nprint(grid.best_params_)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "xgb_params = dict(objective='multi:softprob',                    \n                  max_depth=10, \n                  learning_rate=0.1,\n                  num_class=5)\ndata = xgb.DMatrix(x, y)\nxgb.cv(xgb_params, data, num_boost_round=30,  metrics='mlogloss', verbose_eval=True)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": ""
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}